# Installation et Configuration - Celery & PyTorch ‚úÖ

## R√©sum√© de l'installation

### ‚úÖ PyTorch
- **Version install√©e** : 2.7.1+cu118 (avec support CUDA 11.8)
- **Statut** : Op√©rationnel
- **Tests** : Import et op√©rations de base r√©ussis
- **Note** : CUDA non disponible (pas de GPU compatible d√©tect√©)

### ‚úÖ Celery
- **Version install√©e** : 5.5.3 (immunity)
- **Statut** : Op√©rationnel
- **Broker** : Redis (localhost:6379)
- **Result Backend** : Redis (localhost:6379)
- **Configuration** : `config/celery.py`

### ‚úÖ Redis
- **Statut** : D√©marr√© via Docker Compose
- **Port** : 6379
- **Connexion** : Test√©e et valid√©e

---

## Configuration Celery

### Fichiers cr√©√©s/modifi√©s

1. **`backend/config/celery.py`** ‚ú® NOUVEAU
   - Configuration principale de Celery
   - D√©finition des t√¢ches (debug, audit, nettoyage, m√©triques)
   - Configuration des queues et du routing
   - T√¢ches p√©riodiques

2. **`backend/config/__init__.py`** üîß MODIFI√â
   - Chargement automatique de Celery au d√©marrage de Django

3. **`backend/celery_config.py`** ‚ö†Ô∏è ANCIEN
   - Peut √™tre conserv√© pour r√©trocompatibilit√©
   - Utiliser `config.celery` pour les nouvelles t√¢ches

---

## T√¢ches Celery Enregistr√©es

```
‚úÖ config.celery.debug_task - T√¢che de test/debug
‚úÖ config.celery.audit_quotidien - Audit automatique quotidien (2h)
‚úÖ config.celery.nettoyer_cache - Nettoyage cache (1h)
‚úÖ config.celery.sauvegarder_metriques - Sauvegarde m√©triques (30min)
```

---

## Scripts de D√©marrage Cr√©√©s

### 1. `backend/start_celery_worker.bat`
D√©marre le worker Celery avec :
- V√©rification automatique de Redis
- Activation de l'environnement virtuel
- Configuration optimale pour Windows (pool=solo)

**Usage** :
```bash
cd backend
.\start_celery_worker.bat
```

### 2. `backend/start_celery_beat.bat`
D√©marre Celery Beat pour les t√¢ches p√©riodiques

**Usage** :
```bash
cd backend
.\start_celery_beat.bat
```

### 3. `backend/CELERY_README.md`
Guide complet avec :
- Commandes de d√©marrage
- Utilisation des t√¢ches
- Monitoring
- Troubleshooting
- Configuration production

---

## Tests Cr√©√©s

### 1. `backend/test_celery_simple.py`
Test en mode synchrone (eager)
```bash
python test_celery_simple.py
```

### 2. `backend/test_celery_connection.py`
V√©rification de la connexion Redis/Celery et d√©tection des workers
```bash
python test_celery_connection.py
```

### 3. `backend/test_celery_direct.py` ‚≠ê RECOMMAND√â
Test d'ex√©cution asynchrone avec worker
```bash
python test_celery_direct.py
```

---

## D√©marrage Rapide

### 1. D√©marrer Redis
```bash
# √Ä la racine du projet
docker-compose up -d redis
```

### 2. D√©marrer le Worker Celery
```bash
cd backend
.\start_celery_worker.bat
```

### 3. Tester l'ex√©cution
```bash
# Dans un autre terminal
cd backend
venv\Scripts\activate
python test_celery_direct.py
```

**R√©sultat attendu** :
```
============================================================
Test Direct Celery - send_task
============================================================

1. Envoi de tache via app.send_task...
   [OK] Tache envoyee - ID: b0c4bb59-445d-47b7-991d-b5bac94ae63c
   Status: PENDING

2. Attente du resultat (10 secondes max)...
   [OK] Tache executee avec succes!
   Status: SUCCESS
   Resultat: {'status': 'debug_ok', 'task_id': '...'}

============================================================
TEST REUSSI!
============================================================
```

---

## Utilisation dans le Code

### Import
```python
from config.celery import debug_task, audit_quotidien
# Ou
from config import celery_app
```

### Ex√©cution Asynchrone
```python
# M√©thode 1 : Via la t√¢che directement
result = debug_task.delay()

# M√©thode 2 : Via l'app
result = celery_app.send_task('config.celery.debug_task')

# R√©cup√©rer le r√©sultat
task_result = result.get(timeout=10)
print(f"Status: {result.status}")  # SUCCESS
print(f"Result: {task_result}")    # {'status': 'debug_ok', ...}
```

### V√©rifier le statut
```python
if result.ready():
    if result.successful():
        print(f"R√©sultat: {result.result}")
    else:
        print(f"Erreur: {result.traceback}")
else:
    print("T√¢che en cours...")
```

---

## Commandes Celery Utiles

### Monitoring
```bash
# Inspecter les workers actifs
celery -A config inspect active

# Voir les t√¢ches enregistr√©es
celery -A config inspect registered

# Ping des workers
celery -A config inspect ping

# Statistiques
celery -A config inspect stats
```

### Gestion
```bash
# Purger toutes les t√¢ches en attente
celery -A config purge

# R√©voquer une t√¢che
celery -A config control revoke <task_id>
```

---

## Configuration des Queues

Les t√¢ches sont automatiquement rout√©es vers diff√©rentes queues :

| Queue | Usage | Priorit√© |
|-------|-------|----------|
| `celery` | T√¢ches g√©n√©riques | Normal |
| `audit` | T√¢ches d'audit | Normal |
| `audit_priority` | Audits critiques | Haute |
| `generation` | G√©n√©ration de liasses | Normal |
| `generation_priority` | G√©n√©ration urgente | Haute |
| `balance` | Import de balances | Normal |
| `long_tasks` | T√¢ches longues | Basse |

### D√©marrer un worker pour une queue sp√©cifique
```bash
celery -A config worker -Q audit -l info --pool=solo
```

---

## Troubleshooting

### Redis ne d√©marre pas
```bash
# V√©rifier Docker
docker ps

# Red√©marrer Redis
docker-compose restart redis
```

### Worker ne re√ßoit pas les t√¢ches
1. V√©rifier que Redis fonctionne
2. V√©rifier que le worker utilise `-A config` et non `-A celery_config`
3. V√©rifier les logs du worker

### Erreur "pool=solo not found"
Sur Windows, toujours utiliser `--pool=solo` :
```bash
celery -A config worker -l info --pool=solo
```

---

## Performance

### Configuration Actuelle
- **Prefetch multiplier** : 4 t√¢ches
- **Task acks late** : Activ√© (plus s√ªr)
- **Concurrency** : 8 (solo pool)
- **S√©rialisation** : JSON uniquement
- **Expiration r√©sultats** : 1 heure

### Optimisation Production
```bash
# Augmenter la concurrence
celery -A config worker -l info --concurrency=16

# Plusieurs workers pour diff√©rentes queues
celery -A config worker -Q audit,generation -l info --pool=solo
```

---

## S√©curit√©

‚úÖ **S√©rialisation** : JSON uniquement (pas de pickle)
‚úÖ **Accept content** : JSON uniquement
‚úÖ **Expiration** : R√©sultats expir√©s apr√®s 1 heure
‚úÖ **Task acks late** : Acquittement apr√®s ex√©cution

---

## Prochaines √âtapes

### 1. Cr√©er vos propres t√¢ches
```python
# Dans apps/mon_app/tasks.py
from config import celery_app

@celery_app.task
def ma_tache(param1, param2):
    # Votre code ici
    return {'result': 'success'}
```

### 2. Configurer Celery Beat pour les t√¢ches p√©riodiques
```python
# Dans config/celery.py
@app.on_after_configure.connect
def setup_periodic_tasks(sender, **kwargs):
    sender.add_periodic_task(
        crontab(hour=0, minute=0),  # Minuit
        ma_tache_quotidienne.s(),
        name='Ma t√¢che quotidienne'
    )
```

### 3. Monitoring avec Flower
```bash
pip install flower
celery -A config flower
# Acc√©der √† http://localhost:5555
```

---

## Ressources

- üìö [Documentation Celery](https://docs.celeryproject.org/)
- üêç [PyTorch Documentation](https://pytorch.org/docs/)
- üìñ [Guide complet](backend/CELERY_README.md)

---

## Statut Final

| Composant | Statut | Version |
|-----------|--------|---------|
| PyTorch | ‚úÖ Op√©rationnel | 2.7.1+cu118 |
| Celery | ‚úÖ Op√©rationnel | 5.5.3 |
| Redis | ‚úÖ Op√©rationnel | 7-alpine |
| Configuration | ‚úÖ Compl√®te | config/celery.py |
| Tests | ‚úÖ R√©ussis | 3 scripts de test |
| Documentation | ‚úÖ Compl√®te | CELERY_README.md |

---

**Date de configuration** : 2025-10-09
**Testeur** : Claude Code
**R√©sultat** : ‚úÖ SUCC√àS COMPLET
